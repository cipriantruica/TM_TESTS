From: bnoble+@cs.cmu.edu (Brian Noble) Subject: X Server scanline padding question   I am *almost* done porting XFree86 1.2 to a new piece of display hardware, but have run into a snag I think may be somewhat commonplace, so i am sending a net-feeler.  I have a display that is a non-interlaced, memory mapped, 1-bit 720x280 display.  The server is view of the world, (obtained via xwd | xwud), seems to be exactly what it should be.  However, the displayed version of the framebuffer gives the impression that the server is using scanlines that are too long.  After a bit of experimentation, it seems that the problem was that the server was padding the line out to a word boundry, but the scanline size in the buffer is 90 bytes, which is not exactly divisible by four.  Changing the following defines in mit/server/include/servermd.h:  ----    BITMAP_SCANLINE_PAD  32   LOG2_BITMAP_PAD\t\t5   LOG2_BYTES_PER_SCANLINE_PAD\t2  ---  to:  ---    BITMAP_SCANLINE_PAD  16   LOG2_BITMAP_PAD\t\t4   LOG2_BYTES_PER_SCANLINE_PAD\t2  ---  Was not exactly the right solution.  How do I tell the server either (a) do not pad the scan lines at all (because this server is only being built to run on this particular display), or to pad only to byte boundries?  i am using a customized version of XFree86v1.2, under Mach 3.0.  Thanks Brian 